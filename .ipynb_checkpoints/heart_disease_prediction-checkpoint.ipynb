{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Heart Disease Prediction Project\n",
        "\n",
        "## A CRISP-DM Approach to Binary Classification\n",
        "\n",
        "This notebook follows the Cross-Industry Standard Process for Data Mining (CRISP-DM) methodology to build a predictive model for heart disease diagnosis.\n",
        "\n",
        "---\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "1. [Business Understanding](#1-business-understanding)\n",
        "2. [Data Understanding](#2-data-understanding)\n",
        "3. [Data Preparation](#3-data-preparation)\n",
        "4. [Modeling](#4-modeling)\n",
        "5. [Evaluation](#5-evaluation)\n",
        "6. [Deployment Scenario](#6-deployment-scenario)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pandas'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Import necessary libraries\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
        "                             f1_score, roc_auc_score, confusion_matrix, \n",
        "                             classification_report, roc_curve)\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "# Set style for better-looking plots\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 1. Business Understanding\n",
        "\n",
        "### Real-World Importance\n",
        "\n",
        "Heart disease is the leading cause of death globally, accounting for approximately 17.9 million deaths each year according to the World Health Organization. Early detection and accurate diagnosis are crucial for:\n",
        "\n",
        "- **Preventing fatal outcomes**: Early intervention can significantly reduce mortality rates\n",
        "- **Reducing healthcare costs**: Accurate predictions help allocate medical resources efficiently\n",
        "- **Improving patient outcomes**: Timely treatment can prevent complications and improve quality of life\n",
        "- **Supporting clinical decision-making**: Machine learning models can assist healthcare professionals in making informed diagnostic decisions\n",
        "\n",
        "### Primary Questions of Interest\n",
        "\n",
        "1. **Can we accurately predict the presence of heart disease given patient features?**\n",
        "   - This question addresses the core predictive capability of our model. We aim to build a model that can reliably distinguish between patients with and without heart disease based on clinical and demographic features.\n",
        "\n",
        "2. **Which factors are most strongly associated with heart disease?**\n",
        "   - Understanding feature importance helps identify key risk factors that clinicians should pay attention to. This can inform preventive care strategies and patient education.\n",
        "\n",
        "### Success Criteria\n",
        "\n",
        "For this binary classification problem, we will evaluate our models using multiple metrics:\n",
        "- **Accuracy**: Overall correctness of predictions\n",
        "- **Precision**: Ability to avoid false positives (incorrectly diagnosing healthy patients)\n",
        "- **Recall**: Ability to identify all true cases (avoiding false negatives, which could be fatal)\n",
        "- **F1-Score**: Balanced measure of precision and recall\n",
        "- **ROC-AUC**: Overall discriminative ability of the model\n",
        "\n",
        "Given the medical context, **recall is particularly important** - we want to minimize false negatives (missing actual heart disease cases).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 2. Data Understanding\n",
        "\n",
        "### 2.1 Loading and Initial Inspection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('Heart_Disease_Prediction.csv')\n",
        "\n",
        "# Display first few rows\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "print(df.head())\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "# Display dataset shape\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Number of rows: {df.shape[0]}\")\n",
        "print(f\"Number of columns: {df.shape[1]}\")\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "# Display column names and data types\n",
        "print(\"Column information:\")\n",
        "print(df.info())\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "# Display column names\n",
        "print(\"Column names:\")\n",
        "print(df.columns.tolist())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Missing Values Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "missing_values = df.isnull().sum()\n",
        "missing_percentage = (missing_values / len(df)) * 100\n",
        "\n",
        "missing_df = pd.DataFrame({\n",
        "    'Column': missing_values.index,\n",
        "    'Missing Count': missing_values.values,\n",
        "    'Missing Percentage': missing_percentage.values\n",
        "})\n",
        "\n",
        "missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
        "\n",
        "if len(missing_df) > 0:\n",
        "    print(\"Missing values found:\")\n",
        "    print(missing_df)\n",
        "else:\n",
        "    print(\"‚úì No missing values found in the dataset!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Descriptive Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display descriptive statistics for numerical columns\n",
        "print(\"Descriptive Statistics:\")\n",
        "print(df.describe())\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "# Display descriptive statistics for categorical columns\n",
        "print(\"Categorical columns summary:\")\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "for col in categorical_cols:\n",
        "    print(f\"\\n{col}:\")\n",
        "    print(df[col].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4 Target Variable Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze target variable distribution\n",
        "target_col = 'Heart Disease'\n",
        "print(f\"Target variable: {target_col}\")\n",
        "print(f\"\\nValue counts:\")\n",
        "print(df[target_col].value_counts())\n",
        "print(f\"\\nValue counts (percentage):\")\n",
        "print(df[target_col].value_counts(normalize=True) * 100)\n",
        "\n",
        "# Visualize target distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "ax = sns.countplot(data=df, x=target_col, palette='Set2')\n",
        "plt.title('Distribution of Heart Disease Cases', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Heart Disease Status', fontsize=12)\n",
        "plt.ylabel('Count', fontsize=12)\n",
        "\n",
        "# Add count labels on bars\n",
        "for container in ax.containers:\n",
        "    ax.bar_label(container, fontsize=11)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Check for class imbalance\n",
        "presence_count = (df[target_col] == 'Presence').sum()\n",
        "absence_count = (df[target_col] == 'Absence').sum()\n",
        "imbalance_ratio = max(presence_count, absence_count) / min(presence_count, absence_count)\n",
        "\n",
        "print(f\"\\nClass imbalance ratio: {imbalance_ratio:.2f}\")\n",
        "if imbalance_ratio > 1.5:\n",
        "    print(\"‚ö† Warning: Significant class imbalance detected. Stratification recommended for train/test split.\")\n",
        "else:\n",
        "    print(\"‚úì Classes are relatively balanced.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.5 Visualizations: Histograms for Key Numerical Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select key numerical variables for visualization\n",
        "numerical_cols = ['Age', 'BP', 'Cholesterol', 'Max HR', 'ST depression']\n",
        "\n",
        "# Create histograms\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for idx, col in enumerate(numerical_cols):\n",
        "    axes[idx].hist(df[col], bins=20, edgecolor='black', alpha=0.7, color='skyblue')\n",
        "    axes[idx].set_title(f'Distribution of {col}', fontsize=12, fontweight='bold')\n",
        "    axes[idx].set_xlabel(col, fontsize=10)\n",
        "    axes[idx].set_ylabel('Frequency', fontsize=10)\n",
        "    axes[idx].grid(True, alpha=0.3)\n",
        "\n",
        "# Remove empty subplot\n",
        "fig.delaxes(axes[5])\n",
        "\n",
        "plt.suptitle('Histograms of Key Numerical Variables', fontsize=16, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.6 Boxplots to Detect Outliers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create boxplots for numerical variables\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for idx, col in enumerate(numerical_cols):\n",
        "    box = axes[idx].boxplot(df[col], patch_artist=True, \n",
        "                            boxprops=dict(facecolor='lightblue', alpha=0.7),\n",
        "                            medianprops=dict(color='red', linewidth=2))\n",
        "    axes[idx].set_title(f'Boxplot of {col}', fontsize=12, fontweight='bold')\n",
        "    axes[idx].set_ylabel(col, fontsize=10)\n",
        "    axes[idx].grid(True, alpha=0.3)\n",
        "\n",
        "# Remove empty subplot\n",
        "fig.delaxes(axes[5])\n",
        "\n",
        "plt.suptitle('Boxplots for Outlier Detection', fontsize=16, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print outlier information using IQR method\n",
        "print(\"Outlier Detection (using IQR method):\")\n",
        "print(\"=\"*60)\n",
        "for col in numerical_cols:\n",
        "    Q1 = df[col].quantile(0.25)\n",
        "    Q3 = df[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
        "    print(f\"\\n{col}:\")\n",
        "    print(f\"  Lower bound: {lower_bound:.2f}, Upper bound: {upper_bound:.2f}\")\n",
        "    print(f\"  Number of outliers: {len(outliers)} ({len(outliers)/len(df)*100:.2f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.7 Correlation Heatmap\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for correlation analysis\n",
        "# First, encode the target variable temporarily for correlation\n",
        "df_temp = df.copy()\n",
        "le_temp = LabelEncoder()\n",
        "df_temp['Heart Disease Encoded'] = le_temp.fit_transform(df[target_col])\n",
        "\n",
        "# Select numerical columns for correlation\n",
        "corr_cols = ['Age', 'Sex', 'Chest pain type', 'BP', 'Cholesterol', 'FBS over 120',\n",
        "             'EKG results', 'Max HR', 'Exercise angina', 'ST depression', \n",
        "             'Slope of ST', 'Number of vessels fluro', 'Thallium', 'Heart Disease Encoded']\n",
        "\n",
        "# Calculate correlation matrix\n",
        "correlation_matrix = df_temp[corr_cols].corr()\n",
        "\n",
        "# Create heatmap\n",
        "plt.figure(figsize=(14, 12))\n",
        "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))  # Mask upper triangle\n",
        "sns.heatmap(correlation_matrix, mask=mask, annot=True, fmt='.2f', cmap='coolwarm',\n",
        "            center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8},\n",
        "            vmin=-1, vmax=1)\n",
        "plt.title('Correlation Heatmap (Including Target Variable)', fontsize=16, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Display correlations with target variable\n",
        "print(\"\\nCorrelation with Heart Disease (encoded):\")\n",
        "print(\"=\"*60)\n",
        "target_corr = correlation_matrix['Heart Disease Encoded'].sort_values(ascending=False)\n",
        "target_corr = target_corr[target_corr.index != 'Heart Disease Encoded']\n",
        "print(target_corr)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.8 Data Understanding Summary\n",
        "\n",
        "**Key Observations:**\n",
        "\n",
        "1. **Dataset Size**: The dataset contains 270 samples with 14 features (13 features + 1 target).\n",
        "\n",
        "2. **Target Variable**: \n",
        "   - Binary classification: \"Presence\" vs \"Absence\" of heart disease\n",
        "   - Classes appear to be relatively balanced\n",
        "\n",
        "3. **Features Include**:\n",
        "   - Demographic: Age, Sex\n",
        "   - Clinical measurements: BP (Blood Pressure), Cholesterol, Max HR (Maximum Heart Rate)\n",
        "   - Medical indicators: Chest pain type, EKG results, Exercise angina, ST depression, etc.\n",
        "\n",
        "4. **Data Quality**: \n",
        "   - No missing values detected\n",
        "   - Some outliers may be present in numerical features (to be handled in data preparation)\n",
        "\n",
        "5. **Correlations**: \n",
        "   - Features showing strong correlation with the target will be important for prediction\n",
        "   - Understanding these relationships helps in feature selection and model interpretation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 3. Data Preparation\n",
        "\n",
        "### 3.1 Handle Missing Values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify no missing values (already checked, but double-checking)\n",
        "print(\"Missing values check:\")\n",
        "print(df.isnull().sum().sum())\n",
        "print(\"\\nSince there are no missing values, no imputation is needed.\")\n",
        "print(\"This is ideal as we don't need to make assumptions about missing data.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Encode Categorical Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a copy of the dataframe for preprocessing\n",
        "df_processed = df.copy()\n",
        "\n",
        "# Encode the target variable (Heart Disease)\n",
        "label_encoder = LabelEncoder()\n",
        "df_processed['Heart Disease'] = label_encoder.fit_transform(df_processed['Heart Disease'])\n",
        "\n",
        "# Check the encoding\n",
        "print(\"Target variable encoding:\")\n",
        "print(f\"  'Absence' -> {label_encoder.transform(['Absence'])[0]}\")\n",
        "print(f\"  'Presence' -> {label_encoder.transform(['Presence'])[0]}\")\n",
        "print(\"\\nNote: 0 = Absence, 1 = Presence\")\n",
        "\n",
        "# Display data types to identify which columns need encoding\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Data types:\")\n",
        "print(df_processed.dtypes)\n",
        "\n",
        "# Check unique values in each column to understand categorical vs numerical\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Unique values per column:\")\n",
        "for col in df_processed.columns:\n",
        "    if col != 'Heart Disease':  # Skip target\n",
        "        unique_vals = df_processed[col].unique()\n",
        "        print(f\"{col}: {len(unique_vals)} unique values - {sorted(unique_vals)[:10]}\")\n",
        "\n",
        "# Note: Most columns appear to be already numerical or ordinal\n",
        "# The dataset seems to have been pre-processed, so we'll proceed with scaling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Separate Features and Target\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separate features and target\n",
        "X = df_processed.drop('Heart Disease', axis=1)\n",
        "y = df_processed['Heart Disease']\n",
        "\n",
        "print(f\"Features shape: {X.shape}\")\n",
        "print(f\"Target shape: {y.shape}\")\n",
        "print(f\"\\nFeature columns: {list(X.columns)}\")\n",
        "print(f\"\\nTarget distribution:\")\n",
        "print(y.value_counts())\n",
        "print(f\"\\nTarget distribution (percentage):\")\n",
        "print(y.value_counts(normalize=True) * 100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.4 Train/Test Split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create train/test split with stratification\n",
        "# 80/20 split with stratification to maintain class balance\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, \n",
        "    test_size=0.2, \n",
        "    random_state=RANDOM_STATE, \n",
        "    stratify=y  # Ensures both sets have similar class distribution\n",
        ")\n",
        "\n",
        "print(f\"Training set size: {X_train.shape[0]} samples ({X_train.shape[0]/len(df)*100:.1f}%)\")\n",
        "print(f\"Test set size: {X_test.shape[0]} samples ({X_test.shape[0]/len(df)*100:.1f}%)\")\n",
        "print(f\"\\nTraining set target distribution:\")\n",
        "print(y_train.value_counts())\n",
        "print(f\"\\nTest set target distribution:\")\n",
        "print(y_test.value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.5 Feature Scaling\n",
        "\n",
        "**Justification for Scaling:**\n",
        "- Many machine learning algorithms (especially Logistic Regression) are sensitive to the scale of features\n",
        "- Features like Age, BP, Cholesterol, and Max HR have different ranges\n",
        "- StandardScaler will transform features to have mean=0 and std=1, which helps algorithms converge faster and perform better\n",
        "- We'll fit the scaler only on training data to avoid data leakage\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit scaler on training data only (to avoid data leakage)\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert back to DataFrame for easier handling\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
        "\n",
        "print(\"Feature scaling completed.\")\n",
        "print(f\"\\nScaled training data statistics (first 5 features):\")\n",
        "print(X_train_scaled.iloc[:, :5].describe())\n",
        "print(\"\\nNote: Mean should be ~0 and std should be ~1 for scaled features\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 4. Modeling\n",
        "\n",
        "We will train two classification models:\n",
        "1. **Logistic Regression** - A baseline linear model that's interpretable and fast\n",
        "2. **Random Forest Classifier** - A nonlinear ensemble model that can capture complex patterns\n",
        "\n",
        "Both models will be evaluated using cross-validation to ensure robust performance estimates.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Model 1: Logistic Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create Logistic Regression model with pipeline\n",
        "lr_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('classifier', LogisticRegression(random_state=RANDOM_STATE, max_iter=1000))\n",
        "])\n",
        "\n",
        "# Train the model\n",
        "lr_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Cross-validation evaluation\n",
        "cv_scores_lr = cross_val_score(lr_pipeline, X_train, y_train, \n",
        "                                cv=5, scoring='accuracy')\n",
        "\n",
        "print(\"Logistic Regression - Cross-Validation Results:\")\n",
        "print(f\"  Mean CV Accuracy: {cv_scores_lr.mean():.4f} (+/- {cv_scores_lr.std() * 2:.4f})\")\n",
        "print(f\"  Individual CV scores: {cv_scores_lr}\")\n",
        "\n",
        "# Make predictions on test set\n",
        "y_pred_lr = lr_pipeline.predict(X_test)\n",
        "y_pred_proba_lr = lr_pipeline.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(f\"\\n‚úì Logistic Regression model trained successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Model 2: Random Forest Classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create Random Forest model with pipeline\n",
        "rf_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('classifier', RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        random_state=RANDOM_STATE,\n",
        "        max_depth=10,\n",
        "        min_samples_split=5,\n",
        "        min_samples_leaf=2\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Train the model\n",
        "rf_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Cross-validation evaluation\n",
        "cv_scores_rf = cross_val_score(rf_pipeline, X_train, y_train, \n",
        "                               cv=5, scoring='accuracy')\n",
        "\n",
        "print(\"Random Forest - Cross-Validation Results:\")\n",
        "print(f\"  Mean CV Accuracy: {cv_scores_rf.mean():.4f} (+/- {cv_scores_rf.std() * 2:.4f})\")\n",
        "print(f\"  Individual CV scores: {cv_scores_rf}\")\n",
        "\n",
        "# Make predictions on test set\n",
        "y_pred_rf = rf_pipeline.predict(X_test)\n",
        "y_pred_proba_rf = rf_pipeline.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(f\"\\n‚úì Random Forest model trained successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Feature Importance (Random Forest)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract feature importance from Random Forest\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': rf_pipeline.named_steps['classifier'].feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print(\"Feature Importance (Random Forest):\")\n",
        "print(\"=\"*60)\n",
        "print(feature_importance.to_string(index=False))\n",
        "\n",
        "# Visualize feature importance\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(data=feature_importance, x='Importance', y='Feature', palette='viridis')\n",
        "plt.title('Feature Importance - Random Forest Model', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Importance Score', fontsize=12)\n",
        "plt.ylabel('Feature', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 5. Evaluation\n",
        "\n",
        "We will evaluate both models using multiple metrics to get a comprehensive understanding of their performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.1 Evaluation Metrics for Logistic Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate metrics for Logistic Regression\n",
        "lr_accuracy = accuracy_score(y_test, y_pred_lr)\n",
        "lr_precision = precision_score(y_test, y_pred_lr)\n",
        "lr_recall = recall_score(y_test, y_pred_lr)\n",
        "lr_f1 = f1_score(y_test, y_pred_lr)\n",
        "lr_roc_auc = roc_auc_score(y_test, y_pred_proba_lr)\n",
        "lr_cm = confusion_matrix(y_test, y_pred_lr)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"LOGISTIC REGRESSION - EVALUATION METRICS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Accuracy:  {lr_accuracy:.4f}\")\n",
        "print(f\"Precision: {lr_precision:.4f}\")\n",
        "print(f\"Recall:    {lr_recall:.4f}\")\n",
        "print(f\"F1-Score:  {lr_f1:.4f}\")\n",
        "print(f\"ROC-AUC:   {lr_roc_auc:.4f}\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(lr_cm)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_lr, target_names=['Absence', 'Presence']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 Evaluation Metrics for Random Forest\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate metrics for Random Forest\n",
        "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
        "rf_precision = precision_score(y_test, y_pred_rf)\n",
        "rf_recall = recall_score(y_test, y_pred_rf)\n",
        "rf_f1 = f1_score(y_test, y_pred_rf)\n",
        "rf_roc_auc = roc_auc_score(y_test, y_pred_proba_rf)\n",
        "rf_cm = confusion_matrix(y_test, y_pred_rf)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"RANDOM FOREST - EVALUATION METRICS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Accuracy:  {rf_accuracy:.4f}\")\n",
        "print(f\"Precision: {rf_precision:.4f}\")\n",
        "print(f\"Recall:    {rf_recall:.4f}\")\n",
        "print(f\"F1-Score:  {rf_f1:.4f}\")\n",
        "print(f\"ROC-AUC:   {rf_roc_auc:.4f}\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(rf_cm)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_rf, target_names=['Absence', 'Presence']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.3 Visualizations: Confusion Matrices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create confusion matrix visualizations\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Logistic Regression Confusion Matrix\n",
        "sns.heatmap(lr_cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
        "            xticklabels=['Absence', 'Presence'],\n",
        "            yticklabels=['Absence', 'Presence'])\n",
        "axes[0].set_title('Logistic Regression\\nConfusion Matrix', fontsize=14, fontweight='bold')\n",
        "axes[0].set_ylabel('Actual', fontsize=12)\n",
        "axes[0].set_xlabel('Predicted', fontsize=12)\n",
        "\n",
        "# Random Forest Confusion Matrix\n",
        "sns.heatmap(rf_cm, annot=True, fmt='d', cmap='Greens', ax=axes[1],\n",
        "            xticklabels=['Absence', 'Presence'],\n",
        "            yticklabels=['Absence', 'Presence'])\n",
        "axes[1].set_title('Random Forest\\nConfusion Matrix', fontsize=14, fontweight='bold')\n",
        "axes[1].set_ylabel('Actual', fontsize=12)\n",
        "axes[1].set_xlabel('Predicted', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.4 ROC Curves Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate ROC curves\n",
        "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_pred_proba_lr)\n",
        "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_proba_rf)\n",
        "\n",
        "# Plot ROC curves\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC = {lr_roc_auc:.4f})', \n",
        "         linewidth=2, color='blue')\n",
        "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {rf_roc_auc:.4f})', \n",
        "         linewidth=2, color='green')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier (AUC = 0.50)', linewidth=1)\n",
        "plt.xlabel('False Positive Rate', fontsize=12)\n",
        "plt.ylabel('True Positive Rate', fontsize=12)\n",
        "plt.title('ROC Curves Comparison', fontsize=16, fontweight='bold')\n",
        "plt.legend(loc='lower right', fontsize=11)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.5 Model Comparison Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comparison dataframe\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC'],\n",
        "    'Logistic Regression': [lr_accuracy, lr_precision, lr_recall, lr_f1, lr_roc_auc],\n",
        "    'Random Forest': [rf_accuracy, rf_precision, rf_recall, rf_f1, rf_roc_auc]\n",
        "})\n",
        "\n",
        "comparison_df['Difference'] = comparison_df['Random Forest'] - comparison_df['Logistic Regression']\n",
        "comparison_df['Best Model'] = comparison_df.apply(\n",
        "    lambda row: 'Random Forest' if row['Difference'] > 0 else 'Logistic Regression', axis=1\n",
        ")\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"MODEL COMPARISON SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "print(comparison_df.to_string(index=False))\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "\n",
        "# Determine best model based on multiple criteria\n",
        "best_model_name = 'Random Forest' if rf_roc_auc > lr_roc_auc else 'Logistic Regression'\n",
        "best_model = rf_pipeline if best_model_name == 'Random Forest' else lr_pipeline\n",
        "\n",
        "print(f\"\\nüèÜ BEST MODEL: {best_model_name}\")\n",
        "print(f\"   Selected based on ROC-AUC score (most comprehensive metric)\")\n",
        "print(f\"\\nKey Metrics for Best Model:\")\n",
        "if best_model_name == 'Random Forest':\n",
        "    print(f\"   Accuracy:  {rf_accuracy:.4f}\")\n",
        "    print(f\"   Precision: {rf_precision:.4f}\")\n",
        "    print(f\"   Recall:    {rf_recall:.4f}\")\n",
        "    print(f\"   F1-Score:  {rf_f1:.4f}\")\n",
        "    print(f\"   ROC-AUC:   {rf_roc_auc:.4f}\")\n",
        "else:\n",
        "    print(f\"   Accuracy:  {lr_accuracy:.4f}\")\n",
        "    print(f\"   Precision: {lr_precision:.4f}\")\n",
        "    print(f\"   Recall:    {lr_recall:.4f}\")\n",
        "    print(f\"   F1-Score:  {lr_f1:.4f}\")\n",
        "    print(f\"   ROC-AUC:   {lr_roc_auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.6 Metric Interpretation\n",
        "\n",
        "**Understanding the Metrics:**\n",
        "\n",
        "1. **Accuracy**: The proportion of correct predictions out of all predictions.\n",
        "   - Tells us: Overall, how often is the model correct?\n",
        "   - In our case: Both models achieve high accuracy, indicating good overall performance.\n",
        "\n",
        "2. **Precision**: The proportion of positive predictions that are actually correct.\n",
        "   - Tells us: When the model predicts \"Presence\", how often is it right?\n",
        "   - Important for: Avoiding false alarms (incorrectly diagnosing healthy patients).\n",
        "\n",
        "3. **Recall (Sensitivity)**: The proportion of actual positives that were correctly identified.\n",
        "   - Tells us: Of all patients with heart disease, how many did we catch?\n",
        "   - **Critical for medical diagnosis**: Missing a true case (false negative) could be fatal.\n",
        "\n",
        "4. **F1-Score**: Harmonic mean of precision and recall.\n",
        "   - Tells us: Balanced measure when both precision and recall are important.\n",
        "   - Useful when: We need a single metric that considers both false positives and false negatives.\n",
        "\n",
        "5. **ROC-AUC**: Area under the Receiver Operating Characteristic curve.\n",
        "   - Tells us: How well the model distinguishes between classes across all thresholds.\n",
        "   - Range: 0.5 (random) to 1.0 (perfect). Higher is better.\n",
        "   - **Most comprehensive metric** for binary classification.\n",
        "\n",
        "**Model Selection Rationale:**\n",
        "- We selected the model with the highest ROC-AUC score as it provides the most comprehensive evaluation.\n",
        "- In medical contexts, we also prioritize high recall to minimize false negatives (missing actual heart disease cases).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 6. Deployment Scenario\n",
        "\n",
        "Let's create a realistic new patient scenario and use our best model to make a prediction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a realistic new patient scenario\n",
        "# Example: A 58-year-old male patient with specific clinical measurements\n",
        "new_patient = pd.DataFrame({\n",
        "    'Age': [58],\n",
        "    'Sex': [1],  # 1 = Male\n",
        "    'Chest pain type': [4],  # Typical angina\n",
        "    'BP': [140],  # Blood pressure\n",
        "    'Cholesterol': [250],\n",
        "    'FBS over 120': [0],  # Fasting blood sugar <= 120\n",
        "    'EKG results': [2],\n",
        "    'Max HR': [150],  # Maximum heart rate achieved\n",
        "    'Exercise angina': [1],  # Yes\n",
        "    'ST depression': [2.0],  # ST depression induced by exercise\n",
        "    'Slope of ST': [2],\n",
        "    'Number of vessels fluro': [2],  # Number of major vessels colored by flourosopy\n",
        "    'Thallium': [7]\n",
        "})\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"NEW PATIENT SCENARIO\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nPatient Profile:\")\n",
        "print(f\"  Age: {new_patient['Age'].values[0]} years\")\n",
        "print(f\"  Sex: {'Male' if new_patient['Sex'].values[0] == 1 else 'Female'}\")\n",
        "print(f\"  Blood Pressure: {new_patient['BP'].values[0]} mmHg\")\n",
        "print(f\"  Cholesterol: {new_patient['Cholesterol'].values[0]} mg/dL\")\n",
        "print(f\"  Max Heart Rate: {new_patient['Max HR'].values[0]} bpm\")\n",
        "print(f\"  Exercise Angina: {'Yes' if new_patient['Exercise angina'].values[0] == 1 else 'No'}\")\n",
        "print(f\"  ST Depression: {new_patient['ST depression'].values[0]} mm\")\n",
        "print(f\"  Chest Pain Type: {new_patient['Chest pain type'].values[0]}\")\n",
        "\n",
        "# Make prediction using the best model\n",
        "prediction_proba = best_model.predict_proba(new_patient)[0]\n",
        "prediction = best_model.predict(new_patient)[0]\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MODEL PREDICTION\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nPredicted Class: {prediction}\")\n",
        "print(f\"  {'Presence' if prediction == 1 else 'Absence'} of Heart Disease\")\n",
        "print(f\"\\nPrediction Probabilities:\")\n",
        "print(f\"  Probability of Absence: {prediction_proba[0]:.4f} ({prediction_proba[0]*100:.2f}%)\")\n",
        "print(f\"  Probability of Presence: {prediction_proba[1]:.4f} ({prediction_proba[1]*100:.2f}%)\")\n",
        "\n",
        "# Interpretation\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"INTERPRETATION\")\n",
        "print(\"=\"*70)\n",
        "if prediction == 1:\n",
        "    print(\"\\n‚ö†Ô∏è  The model predicts PRESENCE of heart disease.\")\n",
        "    print(\"   This means the patient is classified as having heart disease.\")\n",
        "    print(\"   Clinical recommendation: Further diagnostic tests and medical consultation recommended.\")\n",
        "    print(f\"   Confidence level: {prediction_proba[1]*100:.1f}%\")\n",
        "else:\n",
        "    print(\"\\n‚úì The model predicts ABSENCE of heart disease.\")\n",
        "    print(\"   This means the patient is classified as not having heart disease.\")\n",
        "    print(\"   Clinical recommendation: Continue routine monitoring and preventive care.\")\n",
        "    print(f\"   Confidence level: {prediction_proba[0]*100:.1f}%\")\n",
        "\n",
        "print(\"\\n‚ö†Ô∏è  IMPORTANT DISCLAIMER:\")\n",
        "print(\"   This model is for educational purposes only.\")\n",
        "print(\"   Medical decisions should always be made by qualified healthcare professionals.\")\n",
        "print(\"   This prediction should not replace professional medical diagnosis.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.1 Save the Best Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create models directory if it doesn't exist\n",
        "os.makedirs('models', exist_ok=True)\n",
        "\n",
        "# Save the best model\n",
        "model_filename = 'models/best_heart_disease_model.pkl'\n",
        "joblib.dump(best_model, model_filename)\n",
        "print(f\"‚úì Best model saved to: {model_filename}\")\n",
        "\n",
        "# Also save the label encoder for future use\n",
        "label_encoder_filename = 'models/label_encoder.pkl'\n",
        "joblib.dump(label_encoder, label_encoder_filename)\n",
        "print(f\"‚úì Label encoder saved to: {label_encoder_filename}\")\n",
        "\n",
        "# Save the scaler as well (though it's part of the pipeline)\n",
        "print(f\"\\nNote: The scaler is included in the pipeline, so no separate scaler file is needed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 7. Conclusion\n",
        "\n",
        "### Summary of Findings\n",
        "\n",
        "1. **Data Quality**: The dataset was clean with no missing values, making preprocessing straightforward.\n",
        "\n",
        "2. **Model Performance**: Both models performed well, with the Random Forest model achieving slightly better overall performance based on ROC-AUC score.\n",
        "\n",
        "3. **Key Features**: The feature importance analysis revealed which clinical indicators are most predictive of heart disease.\n",
        "\n",
        "4. **Clinical Relevance**: The model can assist healthcare professionals in making informed diagnostic decisions, though it should always be used in conjunction with professional medical judgment.\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- **Model Improvement**: \n",
        "  - Hyperparameter tuning using GridSearchCV or RandomizedSearchCV\n",
        "  - Feature engineering to create new meaningful features\n",
        "  - Ensemble methods combining multiple models\n",
        "  \n",
        "- **Deployment Considerations**:\n",
        "  - Create a web application or API for real-time predictions\n",
        "  - Implement model monitoring to track performance over time\n",
        "  - Regular retraining with new data to maintain accuracy\n",
        "\n",
        "- **Further Analysis**:\n",
        "  - Investigate specific feature interactions\n",
        "  - Analyze misclassified cases to understand model limitations\n",
        "  - Explore different algorithms (XGBoost, SVM, Neural Networks)\n",
        "\n",
        "---\n",
        "\n",
        "**Project completed following CRISP-DM methodology.**\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
